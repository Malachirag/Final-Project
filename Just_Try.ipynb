{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYSnN+Rwv3AZszCY7EaHEF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malachirag/Final-Project/blob/main/Just_Try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tbj2bt0RIEjd"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import glob\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "import pickle\n",
        "import os\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "#Data Augmentation\n",
        "def augment(path,IMG_DIM):\n",
        "\n",
        "  datagen = ImageDataGenerator(rotation_range=40,width_shift_range=.2,height_shift_range=.2,shear_range=.2,zoom_range=.2,horizontal_flip=True,fill_mode='nearest')\n",
        "\n",
        "  #to list all directories in a specific folder\n",
        "  directories = os.listdir(path)\n",
        "\n",
        "  files_path = []\n",
        "  labels = []\n",
        "  for i in range(len(directories)):\n",
        "    ls = []\n",
        "    curPath = path +'/' +directories[i] + '/*'\n",
        "    ls = glob.glob(curPath)\n",
        "    temp = []\n",
        "    for img in ls:\n",
        "      x = img_to_array(load_img(img,target_size = IMG_DIM))\n",
        "      x = x.reshape((1,)+x.shape)\n",
        "      temp.append(x)\n",
        "\n",
        "    i = 0\n",
        "    target = 800\n",
        "    for batch in datagen.flow(temp,batch_size=4,save_to_dir=curPath[:-1],save_format='jpg'):\n",
        "      i += 1\n",
        "      if len(ls) + i*4>800:\n",
        "        break\n",
        "\n",
        "#Creating Frame\n",
        "def createFrame(path,IMG_DIM):\n",
        "  train_imgs = []\n",
        "  labels = []\n",
        "  #getting all folder name\n",
        "  directories = os.listdir(path)\n",
        "  for i in range(len(directories)):\n",
        "    ls = []\n",
        "    temp = []\n",
        "    curPath = path +'/' +directories[i] + '/*'\n",
        "    #getting all files name\n",
        "    ls = glob.glob(curPath)\n",
        "    for img in ls:\n",
        "      x = img_to_array(load_img(img,target_size = IMG_DIM))\n",
        "      temp.append(x)\n",
        "\n",
        "    #print(len(ls))\n",
        "    train_imgs  = train_imgs + temp\n",
        "    label = []\n",
        "    label = [i]*len(ls)\n",
        "    labels += label\n",
        "\n",
        "  df = pd.DataFrame(list(zip(train_imgs,labels)))\n",
        "  df = df.sample(frac = 1)\n",
        "  return df\n",
        "\n",
        "def kFold(df):\n",
        "\n",
        "  df['kfold'] = -1\n",
        "  df = df.reset_index(drop=True)\n",
        "  y = df[1]\n",
        "  kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "  for f,(t_,v_) in enumerate(kf.split(X=df,y=y)):\n",
        "    df.loc[v_,'kfold'] = f\n",
        "\n",
        "  return df\n",
        "\n",
        "#Customized CNN models\n",
        "def DenseNet(train_imgs,train_labels,class_no,num_epochs=20):\n",
        "  print(\"-------------------------------------DENSENET--------------------------------------------\")\n",
        "  input_shape_densenet = (128, 128, 3)\n",
        "  densenet_model = keras.applications.DenseNet169(include_top=False,weights=\"imagenet\",input_tensor=None,input_shape=input_shape_densenet,pooling=None)\n",
        "  densenet_model.trainable = True\n",
        "  for layer in densenet_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  layer = keras.layers.Flatten()(densenet_model.output)\n",
        "  layer = keras.layers.Dense(units=1024,activation='relu')(layer)\n",
        "  layer = keras.layers.Dropout(0.2)(layer)\n",
        "  layer = keras.layers.Dense(units=128,activation='relu')(layer)\n",
        "  layer = keras.layers.Dense(units=class_no,activation='softmax')(layer)\n",
        "  model = keras.models.Model(densenet_model.input, outputs=layer)\n",
        "  model.compile(optimizer = keras.optimizers.RMSprop(learning_rate=2e-5),loss='categorical_crossentropy',metrics=['acc'])\n",
        "\n",
        "  history = model.fit(train_imgs, train_labels, batch_size=32, epochs=num_epochs,verbose=1)\n",
        "  print(\"------------------------------------------------------------------------------------------\")\n",
        "  return model\n",
        "\n",
        "def Inception(train_imgs,train_labels,class_no,num_epochs=20):\n",
        "  print(\"-------------------------------------INCEPTION-------------------------------------------\")\n",
        "\n",
        "  pre_trained_model2 = keras.applications.InceptionV3(input_shape = (128,128,3),include_top = False,weights='imagenet')\n",
        "  for layer in pre_trained_model2.layers:\n",
        "\n",
        "    layer.trainable = False\n",
        "  x = keras.layers.Flatten()(pre_trained_model2.output)\n",
        "  x = layers.Dense(1028,activation='relu')(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense(64,activation='relu')(x)\n",
        "  x = layers.Dense(class_no,activation='softmax')(x)\n",
        "  model3 = Model(pre_trained_model2.input,x)\n",
        "  model3.compile(optimizer = RMSprop(learning_rate=2e-5),loss='categorical_crossentropy',metrics=['acc'])\n",
        "  history = model3.fit(x=train_imgs,y=train_labels, epochs = num_epochs, batch_size = 32,verbose=0)\n",
        "  print(\"-----------------------------------------------------------------------------------------\")\n",
        "  return model3\n",
        "\n",
        "def Xception(train_imgs,train_labels,class_no,num_epochs=20):\n",
        "  print(\"-------------------------------------XCEPTION---------------------------------------------\")\n",
        "  pre_trained_model = keras.applications.Xception(input_shape = (128,128,3), include_top=False,weights=\"imagenet\")\n",
        "  for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "  x = keras.layers.Flatten()(pre_trained_model.output)\n",
        "  x = layers.Dense(256,activation='relu')(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense(32,activation='relu')(x)\n",
        "  x = layers.Dense(class_no,activation='softmax')(x)\n",
        "  model1 = Model(pre_trained_model.input,x)\n",
        "  model1.compile(optimizer = RMSprop(learning_rate=2e-5),loss='categorical_crossentropy',metrics=['acc'])\n",
        "  history = model1.fit(x=train_imgs,y=train_labels, epochs = num_epochs, batch_size = 32, verbose=0)\n",
        "  print(\"------------------------------------------------------------------------------------------\")\n",
        "  return model1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import glob\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "import pickle\n",
        "import os\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "\n",
        "#Fuzzy Rank-based Ensemble:\n",
        "def getScore(model,test_imgs):\n",
        "  res = model.predict(test_imgs)\n",
        "  return res\n",
        "\n",
        "def generateRank1(score,class_no):\n",
        "  rank = np.zeros([class_no,1])\n",
        "  scores = np.zeros([class_no,1])\n",
        "  scores = score\n",
        "  for i in range(class_no):\n",
        "      rank[i] = 1 - np.exp(-((scores[i]-1)**2)/2.0)\n",
        "  return rank\n",
        "\n",
        "def generateRank2(score,class_no):\n",
        "  rank = np.zeros([class_no,1])\n",
        "  scores = np.zeros([class_no,1])\n",
        "  scores = score\n",
        "  for i in range(class_no):\n",
        "      rank[i] = 1 - np.tanh(((scores[i]-1)**2)/2)\n",
        "  return rank\n",
        "\n",
        "def doFusion(res1,res2,res3,label,class_no):\n",
        "  cnt = 0\n",
        "  id = []\n",
        "  for i in range(len(res1)):\n",
        "      rank1 = generateRank1(res1[i],class_no)*generateRank2(res1[i],class_no)\n",
        "      rank2 = generateRank1(res2[i],class_no)*generateRank2(res2[i],class_no)\n",
        "      rank3 = generateRank1(res3[i],class_no)*generateRank2(res3[i],class_no)\n",
        "      rankSum = rank1 + rank2 + rank3\n",
        "      rankSum = np.array(rankSum)\n",
        "      scoreSum = 1 - (res1[i] + res2[i] + res3[i])/3\n",
        "      scoreSum = np.array(scoreSum)\n",
        "\n",
        "      fusedScore = (rankSum.T)*scoreSum\n",
        "      cls = np.argmin(rankSum)\n",
        "      if cls<class_no and label[i][cls]== 1:\n",
        "          cnt += 1\n",
        "      id.append(cls)\n",
        "  print(cnt/len(res1))\n",
        "  return id"
      ],
      "metadata": {
        "id": "T11hzDEGIK0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import glob\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "import pickle\n",
        "import os\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "from utils.utils_cnn import *\n",
        "from utils.utils_ensemble import *\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('/content/drive/MyDrive/FINAL YEAR PROJECT/Dataset', type=str, default = '.', help='Directory where the image data is stored')\n",
        "parser.add_argument('10', type=int, default = 20, help='Number of Epochs of training')\n",
        "args = parser.parse_args()\n",
        "\n",
        "path1 = args.data_directory\n",
        "if path1[-1]=='/':\n",
        "  path1 = path1[:-1]\n",
        "\n",
        "num_epochs = args.epochs\n",
        "\n",
        "IMG_WIDTH=128\n",
        "IMG_HEIGHT=128\n",
        "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT,3)\n",
        "\n",
        "df = createFrame(path1,IMG_DIM)\n",
        "df = kFold(df)\n",
        "\n",
        "target_names = os.listdir(path1)\n",
        "num_classes = len(target_names)\n",
        "\n",
        "for i in range(1,5):\n",
        "  print(f\"----------------------------------------------------FOLD NO {i}-------------------------------------------------------\")\n",
        "  dfTrain = df[df['kfold']!=i]\n",
        "  dfTest = df[(df['kfold']==i)]\n",
        "  train_imgs = list(dfTrain[0])\n",
        "  train_imgs = np.array(train_imgs)\n",
        "  train_imgs = train_imgs/255\n",
        "  train_labels = np.array(dfTrain[1])\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(train_labels)\n",
        "  train_labels = encoder.transform(train_labels)\n",
        "  train_labels = np_utils.to_categorical(train_labels)\n",
        "\n",
        "  test_imgs = list(dfTest[0])\n",
        "  test_imgs = np.array(test_imgs)\n",
        "  test_imgs = test_imgs/255\n",
        "  test_labels = np.array(dfTest[1])\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(test_labels)\n",
        "  test_labels = encoder.transform(test_labels)\n",
        "  test_labels = np_utils.to_categorical(test_labels)\n",
        "\n",
        "  model0 = DenseNet(train_imgs,train_labels,class_no=num_classes,num_epochs=num_epochs)\n",
        "  model1 = Inception(train_imgs,train_labels,class_no=num_classes,num_epochs=num_epochs)\n",
        "  model2 = Xception(train_imgs,train_labels,class_no=num_classes,num_epochs=num_epochs)\n",
        "  print(\"BASE LEARNERS ACCURACY-----------1.DENSENET 2.INCEPTION 3.XCEPTION\")\n",
        "  model0.evaluate(test_imgs, test_labels, batch_size=32)\n",
        "  model1.evaluate(test_imgs, test_labels, batch_size=32)\n",
        "  model2.evaluate(test_imgs, test_labels, batch_size=32)\n",
        "\n",
        "  res1 = model1.predict(test_imgs)\n",
        "  res2 = model0.predict(test_imgs)\n",
        "  res3 = model2.predict(test_imgs)\n",
        "  predictedClass = doFusion(res1,res2,res3,test_labels,class_no=num_classes)\n",
        "\n",
        "  leb1 = np.argmax(res1,axis=-1)\n",
        "  leb2 = np.argmax(res2,axis=-1)\n",
        "  leb3 = np.argmax(res3,axis=-1)\n",
        "  actual = np.argmax(test_labels,axis=-1)\n",
        "\n",
        "  print('Densenet-169 base learner')\n",
        "  print(classification_report(actual, leb1,target_names = target_names,digits=4))\n",
        "  print('Inception base learner')\n",
        "  print(classification_report(actual, leb2,target_names = target_names,digits=4))\n",
        "  print('Xception base learner')\n",
        "  print(classification_report(actual, leb3,target_names = target_names,digits=4))\n",
        "\n",
        "  print('Ensembled')\n",
        "  print(classification_report(actual, predictedClass,target_names = target_names,digits=4))\n",
        "\n",
        "\n",
        "  print(f\"--------------------------------------------------END OF FOLD NO {i}--------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "jouUAXtWIPLZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}